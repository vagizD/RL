{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI gym / Farama Foundation Gymnasium\n",
        "\n",
        "[Gym](https://gym.openai.com) — это набор инструментов для разработки и сравнения алгоритмов обучения с подкреплением, который также включает в себя большой [набор окружений](https://gym.openai.com/envs/).\n",
        "\n",
        "[Gymnasium](https://gymnasium.farama.org/) — актуальный форк Gym'а. Имеет смысл по возможности использовать его. Но, т.к. большинство гайдов написаны под старую (pre- 0.21) версию Gym'а, то будьте готовы к [некоторым правкам кода](https://gymnasium.farama.org/content/migration-guide/).\n",
        "\n",
        "Импортируем необходимые библиотеки и настраиваем визуализацию:"
      ],
      "metadata": {
        "id": "DxqMgkwIEmm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "except ModuleNotFoundError:\n",
        "    COLAB = False\n",
        "    pass\n",
        "\n",
        "if COLAB:\n",
        "    !pip -q install \"gymnasium[classic-control, atari, accept-rom-license]\"\n",
        "    !pip -q install piglet\n",
        "    !pip -q install imageio_ffmpeg\n",
        "    !pip -q install moviepy==1.0.3"
      ],
      "metadata": {
        "id": "ZXE82ZoBFCTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_video(folder=\"./video\"):\n",
        "    mp4list = glob.glob(folder + '/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = sorted(mp4list, key=lambda x: x[-15:], reverse=True)[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")"
      ],
      "metadata": {
        "id": "_SoOWeuGFGQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "# Создаем окружение\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "\n",
        "# Инициализируем окружение\n",
        "state, info = env.reset()\n",
        "print(f\"state: {state}\")\n",
        "\n",
        "# Выполняем действие в среде\n",
        "next_state, r, terminated, truncated, info = env.step(0)\n",
        "print(\n",
        "    f\"next_state: {next_state} , r: {r}, \"\n",
        "    f\"terminated: {terminated}, truncated: {truncated}, \"\n",
        "    f\"info: {info}\"\n",
        ")\n",
        "\n",
        "# Закрываем окружение\n",
        "env.close()"
      ],
      "metadata": {
        "id": "M62ZRChUFI5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Основные методы окружения:\n",
        "\n",
        "* ``reset()`` $-$ инициализация окружения, возвращает первое наблюдение (состояние) и доп информацию.  \n",
        "* ``step(a)`` $-$ выполнить в среде действие $\\mathbf{a}$ и получить кортеж: $\\mathbf{\\langle s_{t+1}, r_t, terminated, truncated, info \\rangle}$, где $\\mathbf{s_{t+1}}$ - следующее состояние, $\\mathbf{r_t}$ - вознаграждение, $\\mathbf{terminated}$ - флаг заверешния эпизода, $\\mathbf{truncated}$ — флаг завершения эпизода по step-лимиту, $\\mathbf{info}$ - дополнительная информация\n",
        "\n",
        "### Дополнительные методы:\n",
        "* ``render()`` $-$ визуализация текущего состояния среды\n",
        "* ``close()`` $-$ закрывает окружение\n",
        "\n",
        "\n",
        "### Свойства среды:\n",
        "* ``env.observation_space`` $-$ информация о пространстве состояний\n",
        "* ``env.action_space`` $-$ информация о пространстве действий\n"
      ],
      "metadata": {
        "id": "loyV-mu6FLiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"env.observation_space: {env.observation_space}\")\n",
        "print(f\"env.action_space: {env.action_space}\")"
      ],
      "metadata": {
        "id": "au7-OFAoFPbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Отрисовка\n",
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "print(env.render())\n",
        "plt.imshow(env.render())"
      ],
      "metadata": {
        "id": "05KskreWFTpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Среда ``MountainCar-v0``\n",
        "\n",
        "Информацию о любой среде можно найти в [исходниках](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/mountain_car.py) или на [сайте](https://gymnasium.farama.org/environments/classic_control/mountain_car_continuous/). О ``MountainCar-v0`` мы можем узнать следующее:\n",
        "\n",
        "#### Задание:\n",
        "Автомобиль едет по одномерному треку между двумя холмами. Цель состоит в том, чтобы заехать на правый холм; однако двигатель машины недостаточно мощный, чтобы взобраться на холм за один проход. Следовательно, единственный способ добиться успеха $-$ это двигаться вперед и назад, чтобы набрать обороты.\n",
        "\n",
        "#### Пространство состояний Box(2):\n",
        "\n",
        "\n",
        "\n",
        "Num | Observation  | Min  | Max  \n",
        "----|--------------|------|----   \n",
        "0   | position     | -1.2 | 0.6\n",
        "1   | velocity     | -0.07| 0.07\n",
        "\n",
        "\n",
        "#### Пространство действий Discrete(3):\n",
        "\n",
        "\n",
        "\n",
        "Num | Action|\n",
        "----|-------------|\n",
        "0   | push left   |\n",
        "1   | no push     |\n",
        "2   | push right  |\n",
        "\n",
        "* Вознаграждения: -1 за каждый шаг, пока не достигнута цель\n",
        "\n",
        "* Начальное состояние: Случайная позиция от -0.6 до -0.4 с нулевой скоростью."
      ],
      "metadata": {
        "id": "Ev3mOuDjFnUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример со случайной стратегией:\n",
        "\n",
        "Для выбора действия используется ``env.action_space.sample()``"
      ],
      "metadata": {
        "id": "3q81s6sfFrqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "# создаем окружение с ограничением на число шагов в среде\n",
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\", max_episode_steps=250)\n",
        "# добавляем визуализацию\n",
        "env = RecordVideo(env, \"./video\")\n",
        "\n",
        "# проводим инициализацию и запоминаем начальное состояние\n",
        "s, _ = env.reset()\n",
        "done = False\n",
        "max_steps = 1000\n",
        "steps = 0\n",
        "\n",
        "while not done and steps <= max_steps:\n",
        "    steps += 1\n",
        "\n",
        "    # выполняем действие, получаем s, r, done, info\n",
        "    s, r, done, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "4YSgEFP7FuzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Video\n",
        "\n",
        "Video('video/rl-video-episode-0.mp4', embed=True)"
      ],
      "metadata": {
        "id": "zHFj0GDwFxxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1:\n",
        "В среде MountainCar-v0 мы хотим, чтобы машина достигла флага. Давайте решим эту задачу, не используя обучение с подкреплением. Модифицируйте код функции ```act``` ниже для выполнения этого задания. Функция получает на вход состояние среды и должна вернуть действие."
      ],
      "metadata": {
        "id": "D-GTUCjXF3AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def act(s):\n",
        "    # возможные действий\n",
        "    left, stop, right = 0, 1, 2\n",
        "    # позиция и скорость\n",
        "    position, velocity = s\n",
        "\n",
        "    # пример: можем попробовать всегда ехать вправо\n",
        "    # action = right\n",
        "    ####### Здесь ваш код ########\n",
        "    action = left if velocity < 0 else right\n",
        "    ##############################\n",
        "    return action"
      ],
      "metadata": {
        "id": "YmyDrzkdGOCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\", max_episode_steps=250)\n",
        "# добавляем визуализацию\n",
        "env = RecordVideo(env, \"./video\")\n",
        "\n",
        "# проводим инициализацию и запоминаем начальное состояние\n",
        "s, _ = env.reset()\n",
        "\n",
        "while True:\n",
        "    # выполняем действие, получаем s, r, done, info\n",
        "    s, r, terminated, truncated, _ = env.step(act(s))\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "if s[0] > 0.47:\n",
        "    print(\"Принято!\")\n",
        "else:\n",
        "    print(\"Исправьте функцию выбора действия!\")\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "id": "nw5IlL3mGReD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример случайная стратегия в игре FrozenLake"
      ],
      "metadata": {
        "id": "m6YSuZn7GWAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v1\", max_episode_steps=500, render_mode=\"rgb_array\")\n",
        "env = RecordVideo(env, \"./video\")\n",
        "\n",
        "s, _ = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    s, r, done, *_ = env.step(env.action_space.sample())\n",
        "\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "id": "kI1H1u8AGbvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}